

import streamlit as st
import pandas as pd
import re
from rapidfuzz import fuzz, process
from datetime import datetime
import io

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Correspond√™ncia Protheus-Tasy",
    page_icon="üîó",
    layout="wide"
)

# CSS personalizado para melhor apar√™ncia
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #666;
        text-align: center;
        margin-bottom: 2rem;
    }
    .success-box {
        padding: 1rem;
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        border-radius: 5px;
        color: #155724;
        margin: 1rem 0;
    }
    .error-box {
        padding: 1rem;
        background-color: #f8d7da;
        border: 1px solid #f5c6cb;
        border-radius: 5px;
        color: #721c24;
        margin: 1rem 0;
    }
    .info-box {
        padding: 1rem;
        background-color: #d1ecf1;
        border: 1px solid #bee5eb;
        border-radius: 5px;
        color: #0c5460;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

def normalize_text(text):
    """
    Normaliza o texto para melhorar a compara√ß√£o:
    - Remove caracteres especiais
    - Converte para min√∫sculas
    - Remove espa√ßos extras
    """
    if pd.isna(text):
        return ""
    
    text = str(text).lower()
    # Remove caracteres especiais, mant√©m apenas letras, n√∫meros e espa√ßos
    text = re.sub(r'[^a-z0-9\s]', ' ', text)
    # Remove espa√ßos m√∫ltiplos
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

def validate_excel_file(uploaded_file):
    """
    Valida o arquivo Excel carregado.
    Retorna (success, message, df_protheus, df_de_para)
    """
    try:
        # Ler o arquivo Excel
        xls = pd.ExcelFile(uploaded_file)
        
        # Verificar se as abas existem (case-insensitive)
        sheet_names_lower = {name.lower(): name for name in xls.sheet_names}
        
        if 'protheus' not in sheet_names_lower:
            return False, "‚ùå Aba 'Protheus' n√£o encontrada no arquivo.", None, None
        
        if 'de para almoxarifado' not in sheet_names_lower:
            return False, "‚ùå Aba 'De Para Almoxarifado' n√£o encontrada no arquivo.", None, None
        
        # Ler as abas
        protheus_sheet = sheet_names_lower['protheus']
        de_para_sheet = sheet_names_lower['de para almoxarifado']
        
        # Ler aba Protheus (header na linha 1) - limitar para evitar problemas de mem√≥ria
        # Ler em chunks para arquivos muito grandes
        try:
            df_protheus = pd.read_excel(uploaded_file, sheet_name=protheus_sheet, header=1, nrows=5000)
        except:
            df_protheus = pd.read_excel(uploaded_file, sheet_name=protheus_sheet, header=1)
        
        # Ler aba De Para Almoxarifado - limitar para evitar problemas de mem√≥ria
        try:
            df_de_para = pd.read_excel(uploaded_file, sheet_name=de_para_sheet, header=0, nrows=2000)
        except:
            df_de_para = pd.read_excel(uploaded_file, sheet_name=de_para_sheet, header=0)
        
        # Validar colunas obrigat√≥rias - case insensitive
        protheus_cols = {col.lower(): col for col in df_protheus.columns}
        
        if 'descricao' not in protheus_cols:
            return False, "‚ùå Coluna 'Descricao' n√£o encontrada na aba Protheus.", None, None
        
        if 'codigo' not in protheus_cols:
            return False, "‚ùå Coluna 'Codigo' n√£o encontrada na aba Protheus.", None, None
        
        de_para_cols = {col.lower(): col for col in df_de_para.columns}
        desc_tasy_col = None
        
        for col_lower, col_original in de_para_cols.items():
            if 'descri' in col_lower and 'tasy' in col_lower:
                desc_tasy_col = col_original
                break
        
        if desc_tasy_col is None:
            return False, "‚ùå Coluna 'Descri√ß√£o do Material Tasy' n√£o encontrada na aba De Para Almoxarifado.", None, None
        
        # Padronizar nomes das colunas
        df_protheus = df_protheus.rename(columns={
            protheus_cols['codigo']: 'Codigo',
            protheus_cols['descricao']: 'Descricao'
        })
        
        df_de_para = df_de_para.rename(columns={desc_tasy_col: 'Descricao_Tasy'})
        
        # Adicionar mensagem sobre limita√ß√£o se aplic√°vel
        info_msg = "‚úÖ Arquivo validado com sucesso!"
        if len(df_protheus) >= 5000:
            info_msg += f" (Limitado a {len(df_protheus)} itens Protheus para performance)"
        if len(df_de_para) >= 2000:
            info_msg += f" (Limitado a {len(df_de_para)} itens Tasy para performance)"
        
        return True, info_msg, df_protheus, df_de_para
        
    except Exception as e:
        return False, f"‚ùå Erro ao ler o arquivo: {str(e)}", None, None

def find_matches(df_protheus, df_de_para, threshold):
    """
    Encontra correspond√™ncias entre as descri√ß√µes do Protheus e Tasy.
    """
    results = []
    
    # Remover linhas com descri√ß√µes vazias
    df_protheus_clean = df_protheus[df_protheus['Descricao'].notna()].copy()
    df_de_para_clean = df_de_para[df_de_para['Descricao_Tasy'].notna()].copy()
    
    # Normalizar textos
    df_protheus_clean['Descricao_Normalizada'] = df_protheus_clean['Descricao'].apply(normalize_text)
    df_de_para_clean['Descricao_Tasy_Normalizada'] = df_de_para_clean['Descricao_Tasy'].apply(normalize_text)
    
    # Criar lista de descri√ß√µes Protheus normalizadas para compara√ß√£o
    protheus_descriptions = df_protheus_clean['Descricao_Normalizada'].tolist()
    protheus_codes = df_protheus_clean['Codigo'].tolist()
    protheus_original = df_protheus_clean['Descricao'].tolist()
    
    # Criar barra de progresso
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    total_items = len(df_de_para_clean)
    
    # Para cada descri√ß√£o Tasy, encontrar a melhor correspond√™ncia
    for idx, (_, row) in enumerate(df_de_para_clean.iterrows()):
        tasy_desc = row['Descricao_Tasy']
        tasy_desc_norm = row['Descricao_Tasy_Normalizada']
        
        # Encontrar as melhores correspond√™ncias usando rapidfuzz
        matches = process.extract(
            tasy_desc_norm,
            protheus_descriptions,
            scorer=fuzz.token_sort_ratio,
            limit=3  # Pegar top 3 para detectar m√∫ltiplas correspond√™ncias
        )
        
        # Verificar se h√° m√∫ltiplas correspond√™ncias acima do limiar
        matches_above_threshold = [m for m in matches if m[1] >= threshold]
        
        if matches_above_threshold:
            best_match = matches_above_threshold[0]
            best_match_idx = best_match[2]
            score = best_match[1]
            
            # Verificar se h√° m√∫ltiplas correspond√™ncias muito similares
            revisao_obrigatoria = False
            if len(matches_above_threshold) > 1:
                # Se houver mais de uma correspond√™ncia com score pr√≥ximo (diferen√ßa < 5)
                score_diff = matches_above_threshold[0][1] - matches_above_threshold[1][1]
                if score_diff < 5:
                    revisao_obrigatoria = True
            
            results.append({
                'Codigo_Protheus': protheus_codes[best_match_idx],
                'Descricao_Protheus': protheus_original[best_match_idx],
                'Descricao_Tasy': tasy_desc,
                'Score_Similaridade': round(score, 2),
                'Revisao_Obrigatoria': '‚ö†Ô∏è SIM' if revisao_obrigatoria else 'N√ÉO'
            })
        
        # Atualizar barra de progresso
        progress = (idx + 1) / total_items
        progress_bar.progress(progress)
        status_text.text(f"Processando: {idx + 1} de {total_items} itens ({progress*100:.1f}%)")
    
    progress_bar.empty()
    status_text.empty()
    
    return pd.DataFrame(results)

# Interface principal
st.markdown('<div class="main-header">üîó Correspond√™ncia Inteligente Protheus-Tasy</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-header">Sistema de correspond√™ncia automatizada entre itens dos sistemas Protheus e Tasy</div>', unsafe_allow_html=True)

# Se√ß√£o de upload
st.markdown("### üì§ 1. Upload do Arquivo")
uploaded_file = st.file_uploader(
    "Selecione o arquivo Excel (.xls, .xlsx)",
    type=['xls', 'xlsx'],
    help="O arquivo deve conter as abas 'Protheus' e 'De Para Almoxarifado'"
)

if uploaded_file is not None:
    # Validar o arquivo
    with st.spinner("üîç Validando arquivo..."):
        success, message, df_protheus, df_de_para = validate_excel_file(uploaded_file)
    
    if success:
        st.markdown(f'<div class="success-box">{message}</div>', unsafe_allow_html=True)
        
        # Mostrar pr√©-visualiza√ß√£o das abas
        st.markdown("### üëÄ 2. Pr√©-visualiza√ß√£o dos Dados")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**Aba Protheus**")
            st.dataframe(
                df_protheus[['Codigo', 'Descricao']].head(10),
                use_container_width=True
            )
            st.caption(f"Total de itens: {len(df_protheus)}")
        
        with col2:
            st.markdown("**Aba De Para Almoxarifado**")
            st.dataframe(
                df_de_para[['Descricao_Tasy']].head(10),
                use_container_width=True
            )
            st.caption(f"Total de itens: {len(df_de_para)}")
        
        # Configura√ß√£o de correspond√™ncia
        st.markdown("### ‚öôÔ∏è 3. Configura√ß√£o da Correspond√™ncia")
        
        threshold = st.slider(
            "Limiar de Similaridade (%)",
            min_value=50,
            max_value=100,
            value=80,
            step=5,
            help="Apenas correspond√™ncias com score acima deste valor ser√£o exibidas"
        )
        
        # Bot√£o para iniciar correspond√™ncia
        if st.button("üöÄ Iniciar Correspond√™ncia", type="primary"):
            st.markdown("### üîÑ 4. Processamento")
            
            with st.spinner("üîÑ Processando correspond√™ncias..."):
                df_matches = find_matches(df_protheus, df_de_para, threshold)
            
            if len(df_matches) > 0:
                st.markdown(f'<div class="success-box">‚úÖ Processamento conclu√≠do! {len(df_matches)} correspond√™ncias encontradas.</div>', unsafe_allow_html=True)
                
                # Estat√≠sticas
                st.markdown("### üìä 5. Estat√≠sticas")
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("Total de Correspond√™ncias", len(df_matches))
                
                with col2:
                    revisao_count = len(df_matches[df_matches['Revisao_Obrigatoria'] == '‚ö†Ô∏è SIM'])
                    st.metric("Revis√£o Obrigat√≥ria", revisao_count)
                
                with col3:
                    avg_score = df_matches['Score_Similaridade'].mean()
                    st.metric("Score M√©dio", f"{avg_score:.1f}%")
                
                with col4:
                    high_confidence = len(df_matches[df_matches['Score_Similaridade'] >= 90])
                    st.metric("Alta Confian√ßa (‚â•90%)", high_confidence)
                
                # Filtros
                st.markdown("### üîç 6. Filtros e Visualiza√ß√£o")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    show_only_review = st.checkbox("Mostrar apenas itens para revis√£o", value=False)
                
                with col2:
                    min_score_filter = st.slider(
                        "Filtrar por score m√≠nimo",
                        min_value=0,
                        max_value=100,
                        value=threshold,
                        step=5
                    )
                
                # Aplicar filtros
                df_filtered = df_matches[df_matches['Score_Similaridade'] >= min_score_filter].copy()
                
                if show_only_review:
                    df_filtered = df_filtered[df_filtered['Revisao_Obrigatoria'] == '‚ö†Ô∏è SIM']
                
                # Ordenar por score (decrescente)
                df_filtered = df_filtered.sort_values('Score_Similaridade', ascending=False)
                
                # Exibir tabela interativa
                st.markdown("### üìã 7. Resultados")
                
                # Destacar itens para revis√£o
                def highlight_review(row):
                    if row['Revisao_Obrigatoria'] == '‚ö†Ô∏è SIM':
                        return ['background-color: #fff3cd'] * len(row)
                    return [''] * len(row)
                
                st.dataframe(
                    df_filtered.style.apply(highlight_review, axis=1),
                    use_container_width=True,
                    height=400
                )
                
                st.caption(f"Exibindo {len(df_filtered)} de {len(df_matches)} correspond√™ncias")
                
                # Exporta√ß√£o
                st.markdown("### üíæ 8. Exporta√ß√£o")
                
                # Gerar nome do arquivo com timestamp
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"correspondencias_{timestamp}.xlsx"
                
                # Criar arquivo Excel em mem√≥ria
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    df_filtered.to_excel(writer, index=False, sheet_name='Correspond√™ncias')
                
                excel_data = output.getvalue()
                
                st.download_button(
                    label="üì• Baixar Correspond√™ncias (Excel)",
                    data=excel_data,
                    file_name=filename,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
                
                st.markdown(f'<div class="info-box">üí° O arquivo ser√° salvo como: <strong>{filename}</strong></div>', unsafe_allow_html=True)
                
            else:
                st.markdown('<div class="error-box">‚ö†Ô∏è Nenhuma correspond√™ncia encontrada com o limiar atual. Tente reduzir o limiar de similaridade.</div>', unsafe_allow_html=True)
    
    else:
        st.markdown(f'<div class="error-box">{message}</div>', unsafe_allow_html=True)

else:
    # Instru√ß√µes quando nenhum arquivo foi carregado
    st.markdown("""
    <div class="info-box">
        <h4>üìù Instru√ß√µes de Uso:</h4>
        <ol>
            <li>Fa√ßa upload de um arquivo Excel contendo as abas <strong>'Protheus'</strong> e <strong>'De Para Almoxarifado'</strong></li>
            <li>Aba <strong>Protheus</strong> deve conter as colunas: <strong>Codigo</strong> e <strong>Descricao</strong></li>
            <li>Aba <strong>De Para Almoxarifado</strong> deve conter a coluna: <strong>Descri√ß√£o do Material Tasy</strong></li>
            <li>Ajuste o limiar de similaridade conforme necess√°rio (padr√£o: 80%)</li>
            <li>Clique em <strong>Iniciar Correspond√™ncia</strong> para processar</li>
            <li>Revise os resultados e baixe o arquivo final</li>
        </ol>
        
        <h4>‚ÑπÔ∏è Sobre o Sistema:</h4>
        <ul>
            <li><strong>Algoritmo de Correspond√™ncia:</strong> Utiliza RapidFuzz para compara√ß√£o textual avan√ßada</li>
            <li><strong>Pr√©-processamento:</strong> Normaliza√ß√£o de texto, remo√ß√£o de caracteres especiais</li>
            <li><strong>Revis√£o Obrigat√≥ria:</strong> Itens com m√∫ltiplas correspond√™ncias similares s√£o marcados automaticamente</li>
            <li><strong>Exporta√ß√£o:</strong> Gera arquivo Excel contendo apenas as correspond√™ncias relevantes</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)

# Rodap√©
st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: #666;'>Desenvolvido com ‚ù§Ô∏è usando Streamlit</div>",
    unsafe_allow_html=True
)
